{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking primer, based on script by Faron\n",
    "\n",
    "### Heavily edited at this point by me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some parameter definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ID = 'id'\n",
    "TARGET = 'loss'\n",
    "NFOLDS = 4\n",
    "SEED = 61222\n",
    "NROWS = None\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "TRAIN_FILE = \"{0}/train.csv\".format(DATA_DIR)\n",
    "TEST_FILE = \"{0}/test.csv\".format(DATA_DIR)\n",
    "SUBMISSION_FILE = \"{0}/sample_submission.csv\".format(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188318, 130),(125546, 130)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(TRAIN_FILE, nrows=NROWS)\n",
    "test = pd.read_csv(TEST_FILE, nrows=NROWS)\n",
    "\n",
    "train_loss = train[[ID,TARGET]] # template for saved single regressor outputs\n",
    "y_train = train[TARGET].ravel()\n",
    "\n",
    "#log transform to reduce skewness\n",
    "y_train = np.log(y_train)\n",
    "\n",
    "train.drop([ID, TARGET], axis=1, inplace=True)\n",
    "test.drop([ID], axis=1, inplace=True)\n",
    "\n",
    "print(\"{},{}\".format(train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "train_test = pd.concat((train, test)).reset_index(drop=True)\n",
    "\n",
    "features = train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_onehot(df, cols):\n",
    "    \"\"\"\n",
    "    One-hot encoding is applied to columns specified in a pandas DataFrame.\n",
    "    \n",
    "    Modified from: https://gist.github.com/kljensen/5452382\n",
    "    and: https://gist.github.com/ramhiser/982ce339d5f8c9a769a0\n",
    "    \n",
    "    Details:\n",
    "    \n",
    "    http://en.wikipedia.org/wiki/One-hot\n",
    "    http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "    \n",
    "    @param df pandas DataFrame\n",
    "    @param cols a list of columns to encode\n",
    "    @return a DataFrame with one-hot encoding\n",
    "    \"\"\"\n",
    "    vec = DictVectorizer()\n",
    "    \n",
    "    vec_data = pd.DataFrame(vec.fit_transform(df[cols].to_dict(orient='records')).toarray())\n",
    "    vec_data.columns = vec.get_feature_names()\n",
    "    vec_data.index = df.index\n",
    "    \n",
    "    df = df.drop(cols, axis=1)\n",
    "    df = df.join(vec_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cont1     cont2     cont3     cont4     cont5     cont6     cont7  \\\n",
      "0  0.726300  0.245921  0.187583  0.789639  0.310061  0.718367  0.335060   \n",
      "1  0.330514  0.737068  0.592681  0.614134  0.885834  0.438917  0.436585   \n",
      "2  0.261841  0.358319  0.484196  0.236924  0.397069  0.289648  0.315545   \n",
      "3  0.321594  0.555782  0.527991  0.373816  0.422268  0.440945  0.391128   \n",
      "4  0.273204  0.159990  0.527991  0.473202  0.704268  0.178193  0.247408   \n",
      "\n",
      "     cont8    cont9   cont10   ...    cat99=M  cat99=N  cat99=O  cat99=P  \\\n",
      "0  0.30260  0.67135  0.83510   ...        0.0      0.0      0.0      0.0   \n",
      "1  0.60087  0.35127  0.43919   ...        0.0      0.0      0.0      0.0   \n",
      "2  0.27320  0.26076  0.32446   ...        0.0      0.0      0.0      0.0   \n",
      "3  0.31796  0.32128  0.44467   ...        0.0      0.0      0.0      0.0   \n",
      "4  0.24564  0.22089  0.21230   ...        0.0      0.0      0.0      1.0   \n",
      "\n",
      "   cat99=R  cat99=S  cat99=T  cat99=U  cat9=A  cat9=B  \n",
      "0      0.0      0.0      1.0      0.0     0.0     1.0  \n",
      "1      0.0      0.0      1.0      0.0     0.0     1.0  \n",
      "2      0.0      0.0      0.0      0.0     0.0     1.0  \n",
      "3      0.0      0.0      1.0      0.0     0.0     1.0  \n",
      "4      0.0      0.0      0.0      0.0     0.0     1.0  \n",
      "\n",
      "[5 rows x 1190 columns]\n"
     ]
    }
   ],
   "source": [
    "cats = [feat for feat in features if 'cat' in feat]\n",
    "train_test = encode_onehot(train_test, cats)\n",
    "    \n",
    "print(train_test.head())\n",
    "\n",
    "x_train = np.array(train_test.iloc[:ntrain,:])\n",
    "x_test = np.array(train_test.iloc[ntrain:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sparse matrix\n",
    "x_train = csr_matrix(x_train)\n",
    "x_test = csr_matrix(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf = KFold(ntrain, n_folds=NFOLDS, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SklearnWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        try:\n",
    "            params['seed'] = seed\n",
    "            self.clf = clf(**params)\n",
    "        except TypeError:\n",
    "            try:\n",
    "                params.pop('seed',None)\n",
    "                params['random_state'] = seed\n",
    "                self.clf = clf(**params)\n",
    "            except TypeError:\n",
    "                params.pop('random_state',None)\n",
    "                self.clf = clf(**params)\n",
    "            \n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SGBWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        try:\n",
    "            params['seed'] = seed\n",
    "            self.clf = clf(**params)\n",
    "        except TypeError:\n",
    "            try:\n",
    "                params.pop('seed',None)\n",
    "                params['random_state'] = seed\n",
    "                self.clf = clf(**params)\n",
    "            except TypeError:\n",
    "                params.pop('random_state',None)\n",
    "                self.clf = clf(**params)\n",
    "            \n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train.toarray(), y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class XgbWrapper(object):\n",
    "    def __init__(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 250)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(xgb.DMatrix(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_oof(clf):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 100,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': 12,\n",
    "    'min_samples_leaf': 2\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 100,\n",
    "    'max_features': 0.25,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'n_jobs': -1,\n",
    "    'seed': 0,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.07,\n",
    "    'objective': 'reg:linear',\n",
    "    'max_depth': 6,\n",
    "    'num_parallel_tree': 1,\n",
    "    'min_child_weight': 1,\n",
    "    'eval_metric': 'mae'\n",
    "}\n",
    "\n",
    "# linear regression params\n",
    "lr_params = {\n",
    "    'n_jobs':-1\n",
    "}\n",
    "\n",
    "# ridge regression params\n",
    "rr_params = {\n",
    "    'alpha': 1.0\n",
    "}\n",
    "\n",
    "# elastic net params\n",
    "en_params = {\n",
    "    'alpha': 1.0\n",
    "}\n",
    "\n",
    "# stochastic gradient boosting\n",
    "sgb_params = {\n",
    "    'n_estimators': 50,\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.07,\n",
    "    'max_features': 0.25\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xg = XgbWrapper(seed=SEED, params=xgb_params)\n",
    "et = SklearnWrapper(clf=ExtraTreesRegressor, seed=SEED, params=et_params)\n",
    "rf = SklearnWrapper(clf=RandomForestRegressor, seed=SEED, params=rf_params)\n",
    "\n",
    "lr = SklearnWrapper(clf=LinearRegression, seed=SEED, params=lr_params)\n",
    "rr = SklearnWrapper(clf=Ridge, seed=SEED, params=rr_params)\n",
    "en = SklearnWrapper(clf=ElasticNet, seed=SEED, params=en_params)\n",
    "sgb = SGBWrapper(clf=GradientBoostingRegressor, seed=SEED, params=sgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xg_oof_train, xg_oof_test = get_oof(xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "et_oof_train, et_oof_test = get_oof(et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_oof_train, rf_oof_test = get_oof(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_oof_train, lr_oof_test = get_oof(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rr_oof_train, rr_oof_test = get_oof(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_oof_train, en_oof_test = get_oof(en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sgb_oof_train, sgb_oof_test = get_oof(sgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XG-CV: 0.428684197175055\n",
      "ET-CV: 0.45084699457639427\n",
      "RF-CV: 0.47125714088200527\n",
      "LR-CV: 0.4413113497884676\n",
      "RR-CV: 0.4410594955651067\n",
      "EN-CV: 0.6600409203406471\n"
     ]
    }
   ],
   "source": [
    "print(\"XG-CV: {}\".format(mean_absolute_error(y_train, xg_oof_train)))\n",
    "print(\"ET-CV: {}\".format(mean_absolute_error(y_train, et_oof_train)))\n",
    "print(\"RF-CV: {}\".format(mean_absolute_error(y_train, rf_oof_train)))\n",
    "\n",
    "print(\"LR-CV: {}\".format(mean_absolute_error(y_train, lr_oof_train)))\n",
    "print(\"RR-CV: {}\".format(mean_absolute_error(y_train, rr_oof_train)))\n",
    "print(\"EN-CV: {}\".format(mean_absolute_error(y_train, en_oof_train)))\n",
    "# print(\"SGB-CV: {}\".format(mean_absolute_error(y_train, sgb_oof_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the xg, et, and rf regressors are doing a solid job, and re-running them every time is a waste of time and energy, so let's save them and simply read them in from csv when we want to ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188318, 6),(125546, 6)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.concatenate((xg_oof_train, \n",
    "                          et_oof_train, \n",
    "                          rf_oof_train,\n",
    "                          lr_oof_train,\n",
    "                          rr_oof_train,\n",
    "                          en_oof_train), axis=1)\n",
    "x_test = np.concatenate((xg_oof_test, \n",
    "                         et_oof_test, \n",
    "                         rf_oof_test,\n",
    "                         lr_oof_test,\n",
    "                         rr_oof_test,\n",
    "                         en_oof_test), axis=1)\n",
    "\n",
    "print(\"{},{}\".format(x_train.shape, x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mae:6.82614+0.00107958\ttest-mae:6.82613+0.00334772\n",
      "[10]\ttrain-mae:4.08754+0.000793454\ttest-mae:4.08748+0.00340333\n",
      "[20]\ttrain-mae:2.44845+0.000367166\ttest-mae:2.44833+0.00378233\n",
      "[30]\ttrain-mae:1.47193+0.000279706\ttest-mae:1.47186+0.0034762\n",
      "[40]\ttrain-mae:0.911961+0.000281293\ttest-mae:0.912118+0.00256106\n",
      "[50]\ttrain-mae:0.628162+0.000371504\ttest-mae:0.628667+0.00154099\n",
      "[60]\ttrain-mae:0.503764+0.000379435\ttest-mae:0.504628+0.00069803\n",
      "[70]\ttrain-mae:0.453875+0.000465415\ttest-mae:0.455006+0.000462354\n",
      "[80]\ttrain-mae:0.434418+0.000466007\ttest-mae:0.435763+0.000744276\n",
      "[90]\ttrain-mae:0.426718+0.00043101\ttest-mae:0.428236+0.000988498\n",
      "[100]\ttrain-mae:0.42362+0.000431106\ttest-mae:0.425264+0.00110175\n",
      "[110]\ttrain-mae:0.422232+0.000433657\ttest-mae:0.423989+0.00118558\n",
      "[120]\ttrain-mae:0.421563+0.000443859\ttest-mae:0.423412+0.00121627\n",
      "[130]\ttrain-mae:0.421164+0.000407181\ttest-mae:0.423119+0.00127382\n",
      "[140]\ttrain-mae:0.420901+0.000403718\ttest-mae:0.422951+0.00129153\n",
      "[150]\ttrain-mae:0.420716+0.000400291\ttest-mae:0.42286+0.00130428\n",
      "[160]\ttrain-mae:0.420538+0.000418549\ttest-mae:0.422775+0.00130068\n",
      "[170]\ttrain-mae:0.420386+0.000418156\ttest-mae:0.42271+0.00131362\n",
      "[180]\ttrain-mae:0.420266+0.000430502\ttest-mae:0.422666+0.00131107\n",
      "[190]\ttrain-mae:0.420136+0.000431362\ttest-mae:0.422637+0.00132087\n",
      "[200]\ttrain-mae:0.420021+0.000428577\ttest-mae:0.422622+0.00132525\n",
      "[210]\ttrain-mae:0.41991+0.000420792\ttest-mae:0.422596+0.00133729\n",
      "[220]\ttrain-mae:0.41978+0.00042338\ttest-mae:0.422568+0.00131599\n",
      "[230]\ttrain-mae:0.419683+0.000420311\ttest-mae:0.422571+0.00128923\n",
      "[240]\ttrain-mae:0.41958+0.000413847\ttest-mae:0.422564+0.00129095\n",
      "[250]\ttrain-mae:0.419475+0.000418967\ttest-mae:0.422545+0.00128982\n",
      "[260]\ttrain-mae:0.419381+0.000420985\ttest-mae:0.422534+0.00127986\n",
      "[270]\ttrain-mae:0.419274+0.000425347\ttest-mae:0.422531+0.00126899\n",
      "[280]\ttrain-mae:0.419175+0.000415061\ttest-mae:0.422504+0.00127578\n",
      "[290]\ttrain-mae:0.419088+0.000426248\ttest-mae:0.42251+0.00128028\n",
      "[300]\ttrain-mae:0.418987+0.00043409\ttest-mae:0.422502+0.00128188\n",
      "Ensemble-CV: 0.42250099999999996+0.0012802366968650888\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "\n",
    "xgb_params = {\n",
    "    'seed': SEED,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.6,\n",
    "    'learning_rate': 0.05,\n",
    "    'objective': 'reg:linear',\n",
    "    'max_depth': 4,\n",
    "    'num_parallel_tree': 1,\n",
    "    'min_child_weight': 1,\n",
    "    'eval_metric': 'mae',\n",
    "}\n",
    "\n",
    "res = xgb.cv(xgb_params, dtrain, num_boost_round=500, nfold=4, seed=SEED, stratified=False,\n",
    "             early_stopping_rounds=25, verbose_eval=10, show_stdv=True)\n",
    "\n",
    "best_nrounds = res.shape[0] - 1\n",
    "cv_mean = res.iloc[-1, 0]\n",
    "cv_std = res.iloc[-1, 1]\n",
    "\n",
    "print('Ensemble-CV: {0}+{1}'.format(cv_mean, cv_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbdt = xgb.train(xgb_params, dtrain, best_nrounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(SUBMISSION_FILE)\n",
    "#submission.iloc[:, 1] = gbdt.predict(dtest)\n",
    "submission.iloc[:, 1] = np.exp(gbdt.predict(dtest))\n",
    "submission.to_csv('submissions/ensemble.sub.xgb_rf_et_lr_rr_en.logpred.20161019.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mean\n",
    "submission.iloc[:, 1]=np.exp(np.mean(x_test,axis=1))\n",
    "submission.to_csv('submissions/ensemble.mean.sub.xgb_rf_et_lr_rr_en.logpred.20161019.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
